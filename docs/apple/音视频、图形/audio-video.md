# 音视频基础知识

音视频素材下载：

- [Download Sound Effects](https://offers.adobe.com/en/na/audition/offers/audition_dlc/AdobeAuditionDLCSFX.html)
- [The best free stock videos shared by the Pexels community.](https://www.pexels.com/videos/)

## 音频

声音是一种波动的能量，主要用三个参数表征：频率（单位时间内的振动次数，单位为 Hz）、振幅（发声物体在震动时，偏离中心位置的幅度）、波形（声波的波形形状决定了声音的音色）。

![img-40](/assets/images/violin_overtones-658e1098.png)

当钢琴的键槌触及琴弦时，会产生特定频率和振幅的振动。振动的频率决定了声音的音调，低音符产生低而慢速的频率；高音符产生高而快速的频率。振动的振幅决定了声音的音量。琴弦的振动引起空气分子的碰撞并向四周传播，到达人耳时，带动耳膜以同样的频率和振幅振动；这些振动传递到内耳的耳蜗上，会转换成电信号传递给大脑。

人类可以听见的音频范围是 20 Hz - 20,000 Hz。

声音的数字化包括了三个基本过程：

一、采样：将麦克风转化过来的模拟电信号以某一频率进行离散化的样本采集。采样频率越高，音质越好。由于采样频率不够导致的采集波形与原始波形不够吻合，称为低频失真。根据 Nyquist 定理，采样频率至少是录制的最高频率的两倍，CD 录制的音频采样率为 44,100 Hz。

二、量化：将采集到的样本电压或电流值进行等级量化处理。量化深度越高，音质越好。量化深度一般用 bit 来衡量。CD 音质的量化深度是 16 bits，可以把纵坐标分成 2^16 = 65536 份。

三、编码：将量化值变换成二进制表示，并存储。单位时间内音频数据的比特容量，称为码率，也叫比特率 (bitrate)。用不同的编码方式进行编码，存储容量也不一样，解码所需要的时间也不一样。

脉冲编码调制 (Pulse Code Modulation, PCM) 是指将采样过程中收集的模拟信号数字化。LPCM (Linear Pulse Code Modulation)，指线性量化，即以固定的时间间隔对音频信号的强度进行采样、并数字化成二进制编码。经过 LPCM 采集到的音频数据是未经压缩的。

## 图像

光进入视觉通过以下 3 种形式：光源、透射光、反射光。人眼受到可见光谱范围内的刺激后，通过神经的传导，产生色彩的感觉。

图像的基本属性包括分辨率、颜色深度、颜色模型。

- 分辨率
- 颜色深度：一幅图像中可使用的颜色数的最大值。目前的显示设备只能显示 RGB 色彩即 2^24 种颜色
- 颜色模型：RGB、CMYK、HSB、YUV（YIQ）、CIE Lab

图像按照在计算机中显示时不同的生成方式，可以分为矢量图和点位图。矢量图转换为点位图采用光栅化技术 (Rasterizing)，点位图转换为矢量图用跟踪技术 (Tracing)。

在图像处理中，颜色通道是用来保存图像颜色信息的，RGB 图有 3 个颜色通道；Alpha 通道是用来保存选区的，将选区作为 8 位的灰度图像来保存。

## 视频

我们看到视频是因为人眼的视觉暂留特性。

电视的传输过程：将摄像机输出的 RGB 信号转换为 YUV 信号，传输后重新还原成 RGB 信号显示。

目前世界上流行的彩色电视制式 NTSC、PAL、SECAM，他们的主要区别是扫描频率、周期、颜色模型的不同。

### 分辨率

| 名称          | 分辨率        |
| ------------- | ------------- |
| HD            | 1,280 x 720   |
| Full HD       | 1,920 x 1,080 |
| 2K            | 2,560 x 1,440 |
| 4K            | 3,840 x 2,160 |
| 8K (Ultra HD) | 7,680 × 4,320 |

### 帧率

NTSC：525 线，每秒 29.97 帧，隔行扫描。美国、日本等地使用。

PAL：625 线，每秒 25 帧，隔行扫描。中国、欧洲等地使用。

胶片电影 24 FPS、国内电视 25 FPS、新的数字电影 30 FPS 或者更高，我们不感觉卡顿，但玩游戏时，低于 60 FPS 我们就能感知到卡顿，这是为什么呢？

一、电影的每一帧是带有动态模糊的，它并不是静止的画面，而是快门一次开合的时间段内的成像，这也是为什么我们在给电影暂停、截图时，会出现动态模糊（比如风扇的扇叶）。而游戏的每一帧是由计算机渲染的，并不带有动态模糊。

二、电影的帧之间时间间隔是固定的，但游戏渲染不一定。根据画面的复杂程度，有可能会出现掉帧。

三、游戏的操作延迟会影响体验。游戏是需要交互的，鼠标、键盘等响应时间、加上计算机的运算时间、到显示到画面上，我们才能得到反馈。100 ms 左右的响应时间才能让玩家感觉到“即时性”。

### 封装格式

一个视频文件包含图像和音频，还有字幕、章节信息、元数据等，这些内容需要按照一定的规则组织起来，即封装。常见的封装格式有 MP4、FLV、AVI、MOV、MKV、3GP 等等。

流式封装：TS、FLV 等；索引封装：MP4、MOV、AVI 等。

封装格式之间的转换，只是换一个封装，不需要重新编码，音视频流可以完全复制，可以做到“秒转”格式。

| 封装格式 | 可容纳的**视频编码格式**        |
| -------- | ------------------------------- |
| MP4      | H.264, H.265, MPEG-4            |
| AVI      | MPEG-2, AC-1, H.264, DIVX, XVID |
| MOV      | MPEG-2, XVID, H.264             |
| WMV      | WMV, AC-1                       |
| WebM     | VP8, VP9                        |
| RM/RMVB  | RV, RM                          |
| TS/PS    | MPEG-2, H.264, MPEG-4           |
| MKV      | 可封装所有的视频编码格式        |

### 码率

单位时间内视频数据的比特容量，称为码率，也叫比特率 bitrate。

三种常见压制方式：CBR（固定码率）、VBR（可变码率）、CRF（固定质量）

| 压制方式 | 适用场景                                                                       |
| -------- | ------------------------------------------------------------------------------ |
| CBR      | 编码压力小，直播常用；画面变化很大时，画质会很低。是空间利用率最低的码率选项。 |
| VBR      | 画面变化小的场景码率低，画面变化大的场景码率高。                               |
| CRF      | 以观感画质为目标，码率、文件大小不可预期。                                     |

相同的码率下，花更多的时间压制（编码）视频，压缩率就越高，画质就会越好。在直播场景下，必须保证视频压制的速度，大于 60 帧每秒，才不会出现掉帧。处理非直播的视频时，可以用更多的编码时间，换取高压缩率和高画质。

### 视频压缩

H.264 是 Motion Picture Experts Group (MPEG) 定义的 MPEG-4 的一部分。是目前最常见的视频编码格式。以 H.264 为例，视频压缩是帧内压缩（消除空间维度的冗余信息）和帧间压缩（消除时间维度的冗余信息）的结合。

#### 帧内压缩

帧内压缩就是把每一帧的图像有损压缩。图像压缩的原理，是人眼对于亮度的分辨能力，比对于色度的分辨能力要高得多。

一张 RGB 图片，1280\*720，每个像素需要记录 RGB 颜色信息，每种颜色范围是 0-255，需要 8 bit，也就是一个字节，一个像素点就需要 3 个字节。那么所需的存储空间是 1280\*720\*3/1024/1024 = 2.63 MB。

视频数据是使用 YCbCr 颜色模式的典型案例。YCbCr 也称 YUV，虽然 YUV 并不十分准确，但是读起来比 YCbCr 好读。YCbCr 中，Y 表示明度、C 就是 Chrominance 色度。Cb 就是 blue 和 green 的色度。Cr 就是 red 和 green 的色度。

YCrCb 与 YUV 的定义是相同的。YUV 适用于 PAL 和 SECAM 彩色电视制式的模拟视频图像表示，YCrCb 适用于数字电视和计算机数字视频图像的表示。

YUV 采用明亮度和色度来表示像素的颜色。Y 表示明度（Luminance），U 和 V 表示色度（Chrominance），色度包括色调和饱和度。

和 RGB 类似，YUV 图像的每个像素点都包括了 YUV 分量，但不同的是，它的 Y 和 UV 分量是可以分离的。只有 Y 分量也可以显示一个图像，只不过是黑白的。根据不同的采样格式，可以若干个 Y 分量共用一个 UV 分量。这种减少颜色数据的过程称为色彩二次抽样。

- YUV 4:4:4 YUV 三个分量的采样比例相同，每个像素的三个分量信息都是 8 bit，与 RGB 占用空间一样。
- YUV 4:2:2 Y 和 UV 按照 2:1 的比例采样。每个像素点都采集 Y 分量，每两个像素点采集一个 UV 分量。两个像素点共用一个 UV 分量。
- YUV 4:2:0 （业界常用的）第一行扫描时，YU 按照 2:1 采样；第二行扫描时，YV 按照 2:1 采样。四个像素点共用一个 UV 分量。

![img](/assets/images/ffb45e600338703b703cd59308e19bdd.png)

以上图为例，按照 4:4:4 采样收集到的信息为：

```s
[Y0, U0, V0], [Y1, U1, V1], [Y2, U2, V2], [Y3, U3, V3]
[Y5, U5, V5], [Y6, U6, V6], [Y7, U7, V7], [Y8, U8, V8]
```

按照 4:2:0 时，第一行 Y 和 U 按照 2:1 采样；第二行 Y 和 V 按照 2:1 采样，收集的信息为：

```s
[Y0, U0], [Y1], [Y2, U2], [Y3]
[Y5, V5], [Y6], [Y7, V7], [Y8]
```

使用 YUV 模型一是为了兼容黑白电视；二是利用人眼对彩色细节的分辨率远低于对亮度细节的分辨率，压缩图像以减少存储容量和传输大小。由于现在所有的显示器都采用 RGB 值来驱动，这就要求在显示每个像素之前，需要把 YUV 分量值转换成 RGB 值。

一个未压缩过的视频，仅仅是通过帧内压缩，就可以减小 90%+ 的体积！

#### 帧间压缩

帧间压缩一般是无损的。

I 帧：关键帧，记录完整图像的一帧。解压后就是一张单独的完整的图片。

P 帧：只存储画面变化的信息。无变化的宏块，直接复用；有变化的宏块，记录下变化信息。解码时，参考前面的 I 帧或 P 帧，叠加变化信息，形成完整画面。

B 帧：双向预测帧。参考前后的帧来生成一个完整的画面。几乎不需要存储空间，但其解压过程会耗费较长时间。直播流中通常会放弃 B 帧，原因就是 B 帧需要向后预测，会延长直播的时延。

原始帧之间的变化越大，越难“预测”。

GOP (Group of Pictures)：每一组 IPB 的序列包含了多少帧。同码率下，GOP 值越大，B 帧和 P 帧越多，视频质量越高。
